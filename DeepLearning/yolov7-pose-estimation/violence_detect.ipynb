{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["blSlmBMdwwE5"],"authorship_tag":"ABX9TyPfTdgbkNqlcTXpFzeSYiVZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## 1. Custom data 및 소스코드 사용 위한 Google Drive 연동"],"metadata":{"id":"mear3tCjvSFm"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wexzTfS3vNrO","executionInfo":{"status":"ok","timestamp":1686123254188,"user_tz":-540,"elapsed":27385,"user":{"displayName":"유다현","userId":"17498635122198972007"}},"outputId":"b185981f-5882-4256-cc3d-f2f5d9e597b9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/IoT_capstone/yolov7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIrH5SE2vZAp","executionInfo":{"status":"ok","timestamp":1686123254189,"user_tz":-540,"elapsed":4,"user":{"displayName":"유다현","userId":"17498635122198972007"}},"outputId":"3b987946-1c0e-4e6e-c6a9-a3a289c2aef8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/IoT_capstone/yolov7\n"]}]},{"cell_type":"markdown","source":["##2. 필요한 라이브러리"],"metadata":{"id":"LYf-Vh03vaVO"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"Xwh7POqcqfmC","executionInfo":{"status":"ok","timestamp":1686123272490,"user_tz":-540,"elapsed":18304,"user":{"displayName":"유다현","userId":"17498635122198972007"}}},"outputs":[],"source":["import cv2\n","import time\n","import torch\n","import argparse\n","import numpy as np\n","from utils.datasets import letterbox\n","from utils.torch_utils import select_device\n","from models.experimental import attempt_load\n","from utils.plots import output_to_keypoint, plot_skeleton_kpts, plot_one_box_kpt, colors\n","from utils.general import non_max_suppression_kpt, strip_optimizer\n","from torchvision import transforms\n","import tensorflow\n","from PIL import ImageFont, ImageDraw, Image\n","import os"]},{"cell_type":"code","source":["def load_classes(path):\n","    with open(path,'r') as f:\n","        names = f.read().split('\\n')\n","        #filter통해 빈 string을 지우고 리스트에 class 저장함\n","    return list(filter(None, names))"],"metadata":{"id":"L1S0rgY9qnR0","executionInfo":{"status":"ok","timestamp":1686123272491,"user_tz":-540,"elapsed":14,"user":{"displayName":"유다현","userId":"17498635122198972007"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 3. Firebase 연동 코드"],"metadata":{"id":"MJSuBmrLJMKu"}},{"cell_type":"code","source":["import firebase_admin\n","from firebase_admin import credentials\n","from firebase_admin import firestore\n","\n","cred = credentials.Certificate('./flutter-4798c-firebase-adminsdk-apes2-583e445d37.json')\n","PROJECT_ID = 'flutter-4798c'\n","default_app = firebase_admin.initialize_app(cred, {\n","    'storageBucket': f'{PROJECT_ID}.appspot.com'\n","})\n","db = firestore.client()\n","db_ref = db.collection('detect').document(\"yolov5\")"],"metadata":{"id":"oS3zixkyJI3W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Parameters"],"metadata":{"id":"UYSpM1eWvf2w"}},{"cell_type":"code","source":["poseweight = '/content/drive/MyDrive/IoT_capstone/yolov7/yolov7-w6-pose.pt' #yolov7 weight파일\n","source = '/content/drive/MyDrive/IoT_capstone/8.mp4' #테스트할 영상 위치\n","device = 'cuda'\n","hide_conf = False\n","hide_labels = False\n","line_thickness = 3\n","\n","sequence = np.empty(51)\n","pose_name = '' #LSTM 출력값 저장할 string 변수\n","frame_count = 0\n","actions = np.array(['violence', 'nonviolence']) #행동 action변수에 정의"],"metadata":{"id":"ZQmmVv42uteE","executionInfo":{"status":"ok","timestamp":1686123708728,"user_tz":-540,"elapsed":2,"user":{"displayName":"유다현","userId":"17498635122198972007"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["##4.weight 파일 가져오기"],"metadata":{"id":"VNG3JNAhwVmZ"}},{"cell_type":"code","source":["model = attempt_load(poseweight, map_location=device) #yolov7 weight파일 가져오기\n","_ = model.eval() #평가 모드\n","names = model.module.names if hasattr(model, 'module') else model.names\n","\n","lstm_model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/IoT_capstone/model/thirdweight.h5\") #LSTM weight파일 가져오기\n","\n","capture = cv2.VideoCapture(source)\n","if capture.isOpened() == False:\n","    print(\"Video can;t open. Please check video path again\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vhb4OQHRuwM5","executionInfo":{"status":"ok","timestamp":1686123711930,"user_tz":-540,"elapsed":2277,"user":{"displayName":"유다현","userId":"17498635122198972007"}},"outputId":"7772da78-619d-449c-d1a3-f7798bd161e1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Fusing layers... \n"]}]},{"cell_type":"markdown","source":["## 5. 영상처리에 필요한 parameters"],"metadata":{"id":"D7NEx_81wshR"}},{"cell_type":"code","source":["frame_count = 0\n","frame_width = int(capture.get(3)/2) #video capture의 width 구해서 반으로 자른 크기로 영상 출력하기 \n","frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","j = 1\n","seq = 20 #20frame 기준으로 저장"],"metadata":{"id":"rjpYDZrpux38","executionInfo":{"status":"ok","timestamp":1686123712599,"user_tz":-540,"elapsed":3,"user":{"displayName":"유다현","userId":"17498635122198972007"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Define the codec and create VideoWriter object\n","# Define the codec and create VideoWriter object\n","# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use other codecs as well\n","fourcc = cv2.VideoWriter_fourcc(*'h264')\n","fps = 7\n","output_video = cv2.VideoWriter('output2.mp4', fourcc, fps, (frame_width, frame_height))"],"metadata":{"id":"c_UvBRdZhEty","executionInfo":{"status":"ok","timestamp":1686123712599,"user_tz":-540,"elapsed":2,"user":{"displayName":"유다현","userId":"17498635122198972007"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["##6. 영상 read해서 test 시작"],"metadata":{"id":"blSlmBMdwwE5"}},{"cell_type":"code","source":["while(capture.isOpened):\n","    #영상 read시작함\n","    print(f\"Frame {frame_count+1} Processing\")\n","    ret, frame = capture.read()\n","\n","    if ret:\n","        org_image = frame\n","        image = cv2.cvtColor(org_image,cv2.COLOR_BGR2RGB)\n","        image = letterbox(image, (frame_width), stride=64, auto=True)[0]\n","        image = transforms.ToTensor()(image)\n","        image = torch.tensor(np.array([image.numpy()]))\n","\n","        image = image.to(device)\n","        image = image.float()\n","\n","        with torch.no_grad():  #get predictions\n","            output_data, _ = model(image)\n","\n","        output_data = non_max_suppression_kpt(output_data,   #Apply non max suppression\n","                                            0.70,   # Conf. Threshold.\n","                                            0.65, # IoU Threshold.\n","                                            nc=model.yaml['nc'], # Number of classes.\n","                                            nkpt=model.yaml['nkpt'], # Number of keypoints.\n","                                            kpt_label=True)\n","        output = output_to_keypoint(output_data)\n","        im0 = image[0].permute(1, 2, 0) * 255 # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n","        im0 = im0.cpu().numpy().astype(np.uint8)\n","        \n","        im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR) #reshape image format to (BGR)\n","        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","        \n","        for i, pose in enumerate(output_data):\n","            #객체 감지\n","            if len(output_data): #프레임 있다면\n","                for c in pose[:,5].unique():\n","                    #객체 감지 되는동안\n","                    n = (pose[:,5]==c).sum()\n","                    print(f\"No of Object in Current Frame: {n}\")\n","                \n","                for det_index, (*xyxy, conf, cls) in enumerate(reversed(pose[:,:6])):\n","                    c = int(cls)\n","                    kpts = pose[det_index, 6:]\n","                    label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n","                    plot_one_box_kpt(xyxy, im0, label=label, color=colors(c, True), \n","                                        line_thickness=line_thickness,kpt_label=True, kpts=kpts, steps=3, \n","                                        orig_shape=im0.shape[:2])\n","                \n","                if j<=seq:\n","                    for idx in range(output.shape[0]):\n","                        kpts = output[idx, 7:].T\n","                        plot_skeleton_kpts(im0, kpts, 3)\n","                        sequence = np.vstack([sequence,kpts])\n","                        print(\"shape: \",sequence.shape)\n","                    \n","                        if sequence.shape == (20,51):  \n","                                result = lstm_model.predict(np.expand_dims(sequence, axis=0))\n","                                print(\"result: \",result)\n","                                sequence = np.empty(51)\n","                                pose_name = actions[np.argmax(result)]\n","                                print(pose_name)\n","\n","                                if pose_name == 'violence':\n","                                        print(\"폭력이 감지되었어요!\")\n","                                        db_ref.update({'detect': 'true'}) # firebase\n","\n","                                elif pose_name == 'nonviolence':\n","                                    print(\"폭력이 감지되지 않았아요!\")\n","                                    db_ref.update({'detect': 'False'}) # firebase\n","                                else:\n","                                    print(pose_name)\n","                                db_ref.update({'detect': 'False'}) # firebase\n","        cv2.imshow(\"Violence detect result\", im0)\n","        # if cv2.waitKey(1)==ord('c') : # 1 millisecond\n","        #     break\n","    else:\n","        break"],"metadata":{"id":"2KjnuENBuzNy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1685255948056,"user_tz":-540,"elapsed":44533,"user":{"displayName":"유다현","userId":"17498635122198972007"}},"outputId":"7b10209e-20bd-49cd-ddab-71e7879d5d24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 1s 1s/step\n","result:  [[    0.99999  6.4791e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 20ms/step\n","result:  [[    0.99996  3.9419e-05]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[          1  3.4499e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (7, 51)\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (9, 51)\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (15, 51)\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (17, 51)\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (19, 51)\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[    0.99998  2.0488e-05]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (2, 51)\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (5, 51)\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (8, 51)\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (11, 51)\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (13, 51)\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (16, 51)\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (18, 51)\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[          1  1.9694e-06]]\n","violence\n","폭력이 감지되었어요!\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (3, 51)\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (7, 51)\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (9, 51)\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (12, 51)\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (14, 51)\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (17, 51)\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (19, 51)\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[          1  2.4079e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (3, 51)\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (16, 51)\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 24ms/step\n","result:  [[          1  2.2947e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 2\n","shape:  (14, 51)\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[          1  1.8622e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 21ms/step\n","result:  [[          1  2.0769e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[    0.99999  7.3901e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[    0.99999  8.8421e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 24ms/step\n","result:  [[    0.99999  7.1665e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 24ms/step\n","result:  [[    0.99998  1.8586e-05]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[    0.99971  0.00029419]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-3fd2e476cfa7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#영상 read시작함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Frame {frame_count+1} Processing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["##7. 영상 저장까지 하는 버전"],"metadata":{"id":"0KOAStC0iZ4u"}},{"cell_type":"code","source":["violence_detected = False  # Variable to track violence detection\n","violence_color = (0, 0, 255)  # Color for indicating violence\n","nonviolence_color = (0, 255, 0)  # Color for indicating non-violence\n","\n","while capture.isOpened:\n","    # 영상 read 시작함\n","    print(f\"Frame {frame_count+1} Processing\")\n","    ret, frame = capture.read()\n","\n","    if ret:\n","        org_image = frame\n","        image = cv2.cvtColor(org_image, cv2.COLOR_BGR2RGB)\n","        image = letterbox(image, (frame_width), stride=64, auto=True)[0]\n","        image = transforms.ToTensor()(image)\n","        image = torch.tensor(np.array([image.numpy()]))\n","\n","        image = image.to(device)\n","        image = image.float()\n","\n","        with torch.no_grad():  # get predictions\n","          output_data, _ = model(image)\n","\n","        # if isinstance(output_data, torch.Tensor):\n","        #     output_data = [output_data]\n","\n","        output_data = non_max_suppression_kpt(output_data,  # Apply non-max suppression\n","                                              0.70,  # Conf. Threshold.\n","                                              0.65,  # IoU Threshold.\n","                                              nc=model.yaml['nc'],  # Number of classes.\n","                                              nkpt=model.yaml['nkpt'],  # Number of keypoints.\n","                                              kpt_label=True)\n","\n","        output = output_to_keypoint(output_data)\n","        im0 = image[0].permute(1, 2, 0) * 255  # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n","        im0 = im0.cpu().numpy().astype(np.uint8)\n","\n","        im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR)  # reshape image format to (BGR)\n","        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","\n","        for i, pose in enumerate(output_data):\n","            # 객체 감지\n","            if len(output_data):  # 프레임이 있다면\n","                for c in pose[:, 5].unique():\n","                    # 객체 감지되는 동안\n","                    n = (pose[:, 5] == c).sum()\n","                    print(f\"No of Object in Current Frame: {n}\")\n","\n","                for det_index, (*xyxy, conf, cls) in enumerate(reversed(pose[:, :6])):\n","                    c = int(cls)\n","                    kpts = pose[det_index, 6:]\n","                    label = None if hide_labels else (model.names[c] if hide_conf else f'{model.names[c]} {conf:.2f}')\n","                    plot_one_box_kpt(xyxy, im0, label=label, color=colors(c, True),\n","                                     line_thickness=line_thickness, kpt_label=True, kpts=kpts, steps=3,\n","                                     orig_shape=im0.shape[:2])\n","\n","                    if j <= seq:\n","                        for idx in range(output.shape[0]):\n","                            kpts = output[idx, 7:].T\n","                            plot_skeleton_kpts(im0, kpts, 3)\n","                            sequence = np.vstack([sequence, kpts])\n","                            print(\"shape: \", sequence.shape)\n","\n","                            if sequence.shape == (20, 51):\n","                                result = lstm_model.predict(np.expand_dims(sequence, axis=0))\n","                                print(\"result: \", result)\n","                                sequence = np.empty(51)\n","                                pose_name = actions[np.argmax(result)]\n","                                print(pose_name)\n","\n","                                if pose_name == 'violence':\n","                                    print(\"폭력이 감지되었어요!\")\n","                                    cv2.putText(im0, \"폭력이 감지되었어요!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n","                                                violence_color, 2)\n","                                    violence_detected = True\n","                                elif pose_name == 'nonviolence':\n","                                    print(\"폭력이 감지되지 않았아요!\")\n","                                    cv2.putText(im0, \"폭력이 감지되지 않았어요!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n","                                                nonviolence_color, 2)\n","                                    violence_detected = False\n","\n","                    output_video.write(im0)  # Write frame with detection to output video\n","\n","    else:\n","        break\n","\n","# Release the VideoWriter object\n","output_video.release()"],"metadata":{"id":"SWQ35w3iKlsV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686123741996,"user_tz":-540,"elapsed":26542,"user":{"displayName":"유다현","userId":"17498635122198972007"}},"outputId":"09366937-5223-4d5f-eb27-a7399796ddfb"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 2s 2s/step\n","result:  [[          1  2.0316e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[    0.99999  7.0086e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[          1  2.4729e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[    0.99999  5.0531e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[    0.99999  1.1954e-05]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[    0.99978  0.00021887]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[    0.99998  1.5406e-05]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 24ms/step\n","result:  [[          1  3.0548e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[          1  2.0047e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 50ms/step\n","result:  [[          1  3.3253e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 47ms/step\n","result:  [[          1  1.8387e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 74ms/step\n","result:  [[    0.99999   5.073e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 23ms/step\n","result:  [[          1  1.9748e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 21ms/step\n","result:  [[    0.99999  6.3388e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (9, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (10, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (11, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (12, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (13, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (14, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (15, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (16, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (17, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (18, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (19, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (20, 51)\n","1/1 [==============================] - 0s 22ms/step\n","result:  [[          1  3.6148e-06]]\n","violence\n","폭력이 감지되었어요!\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (2, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (3, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (4, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (5, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (6, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (7, 51)\n","Frame 1 Processing\n","No of Object in Current Frame: 1\n","shape:  (8, 51)\n","Frame 1 Processing\n"]}]}]}